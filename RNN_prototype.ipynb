{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_prototype.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seemanthini-n/DeepLearning.AI/blob/master/RNN_prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pg79xMSYzsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgJBw_W_Y-Yk",
        "colab_type": "code",
        "outputId": "a54d3497-e9de-4a14-ca23-1a3c93a6685c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPwWdtTeZLf-",
        "colab_type": "code",
        "outputId": "5f7f46a4-d830-4930-8ce3-11bf75b82aa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path_to_file='/content/djmh.txt' \n",
        "\n",
        "import re\n",
        "inputtext = open('/content/djmh.txt').read()\n",
        "cleantext = re.sub('[^a-zA-Z0-9\\n\\.]', ' ', inputtext)\n",
        "open('/content/djmh.txt', 'w').write(cleantext)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140891"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDSCtD_0Zmys",
        "colab_type": "code",
        "outputId": "241f3128-af2a-4805-df06-7050ed3ac7d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 140891 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLnnZw5GZstx",
        "colab_type": "code",
        "outputId": "76cd2549-b789-4c6c-cc6b-f6dd94aad6d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    START OF THIS PROJECT GUTENBERG EBOOK THE STRANGE CASE OF DR. JEKYLL AND MR. HYDE    \n",
            "\n",
            "STORY OF THE DOOR\n",
            "\n",
            "Mr. Utterson the lawyer was a man of a rugged countenance that was\n",
            "never lighted by a smile  cold  scanty and embarrassed in discourse \n",
            "back\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHI2J-lhZxBJ",
        "colab_type": "code",
        "outputId": "7c50253e-1408-400f-c4b4-088d8fb53aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print ('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igdDldxOZ11c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iYR4AHDZ6b4",
        "colab_type": "code",
        "outputId": "0a5ab036-2d0c-4723-e15e-b239140db73d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '.' :   2,\n",
            "  '0' :   3,\n",
            "  '1' :   4,\n",
            "  '2' :   5,\n",
            "  '4' :   6,\n",
            "  '5' :   7,\n",
            "  '8' :   8,\n",
            "  'A' :   9,\n",
            "  'B' :  10,\n",
            "  'C' :  11,\n",
            "  'D' :  12,\n",
            "  'E' :  13,\n",
            "  'F' :  14,\n",
            "  'G' :  15,\n",
            "  'H' :  16,\n",
            "  'I' :  17,\n",
            "  'J' :  18,\n",
            "  'K' :  19,\n",
            "  ...\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwLbtlpIaCTg",
        "colab_type": "code",
        "outputId": "e8916aaf-01ef-424c-afae-b83de03f8299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Show how the first 13 characters from the text are mapped to integers\n",
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'    START OF ' ---- characters mapped to int ---- > [ 1  1  1  1 27 28  9 26 28  1 23 14  1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWBBJtggaE1R",
        "colab_type": "code",
        "outputId": "d833ee58-b34a-4251-b691-3c5acb8ab8d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n",
            " \n",
            " \n",
            "S\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NwACrXYaP1_",
        "colab_type": "code",
        "outputId": "3a06a173-e1c4-4fa3-855b-89c9af84bdbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'    START OF THIS PROJECT GUTENBERG EBOOK THE STRANGE CASE OF DR. JEKYLL AND MR. HYDE    \\n\\nSTORY OF T'\n",
            "'HE DOOR\\n\\nMr. Utterson the lawyer was a man of a rugged countenance that was\\nnever lighted by a smile '\n",
            "' cold  scanty and embarrassed in discourse \\nbackward in sentiment  lean  long  dusty  dreary and yet '\n",
            "'somehow\\nlovable. At friendly meetings  and when the wine was to his taste \\nsomething eminently human '\n",
            "'beaconed from his eye  something indeed which\\nnever found its way into his talk  but which spoke not '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3U79JM9aZlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4OO4MrTadxF",
        "colab_type": "code",
        "outputId": "42a056ce-9d22-4387-de6f-86ad997a541f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  '    START OF THIS PROJECT GUTENBERG EBOOK THE STRANGE CASE OF DR. JEKYLL AND MR. HYDE    \\n\\nSTORY OF '\n",
            "Target data: '   START OF THIS PROJECT GUTENBERG EBOOK THE STRANGE CASE OF DR. JEKYLL AND MR. HYDE    \\n\\nSTORY OF T'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNFc5OHgah5N",
        "colab_type": "code",
        "outputId": "211796fd-4c2f-4f03-b271-98ad057a74c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 1 (' ')\n",
            "  expected output: 1 (' ')\n",
            "Step    1\n",
            "  input: 1 (' ')\n",
            "  expected output: 1 (' ')\n",
            "Step    2\n",
            "  input: 1 (' ')\n",
            "  expected output: 1 (' ')\n",
            "Step    3\n",
            "  input: 1 (' ')\n",
            "  expected output: 27 ('S')\n",
            "Step    4\n",
            "  input: 27 ('S')\n",
            "  expected output: 28 ('T')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbWpLoWCamCd",
        "colab_type": "code",
        "outputId": "e239b839-ee7a-4051-f052-4a68db6f390e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opnP7pcMauB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFmokwxYa11S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B15N4Qk7a32r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUBOrdova-W9",
        "colab_type": "code",
        "outputId": "f53cea29-2bfd-482b-cbe3-f10b073153c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 59) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofMr1J-YbA8g",
        "colab_type": "code",
        "outputId": "7313b687-f1c7-4fa3-db0d-395e035f59b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (64, None, 256)           15104     \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (64, None, 59)            60475     \n",
            "=================================================================\n",
            "Total params: 4,013,883\n",
            "Trainable params: 4,013,883\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAAP5r_wbGLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1856GSUmbIzd",
        "colab_type": "code",
        "outputId": "51a322e9-3ab1-41a7-bc78-abd228afe7e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([32, 29, 18, 21, 20, 29, 49, 37, 54, 54, 21,  9, 27,  6, 50, 26,  2,\n",
              "       13, 34, 32, 58, 56, 45,  4, 51, 46, 56,  1, 38, 43, 43, 34, 17, 25,\n",
              "       32, 47,  0, 54, 54, 54,  5, 53,  4, 13, 19,  0, 35, 19, 52, 54, 45,\n",
              "        1, 52, 12, 29,  2,  1, 31, 49, 26, 29, 37, 26, 45, 56, 20,  4,  3,\n",
              "       51, 38, 48, 45, 38,  2,  4, 40,  0, 53, 41, 15, 56, 52, 21, 37, 23,\n",
              "       51,  3, 44, 44, 21, 14, 21, 16,  3, 35,  4, 54, 51, 29, 13])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja_4w2lvbKMk",
        "colab_type": "code",
        "outputId": "3daf06ed-e31e-4e85-b694-8b79ab6c888d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " ' unlocked the door and disappeared into\\nthe house.\\n\\nThe lawyer stood awhile when Mr. Hyde had left h'\n",
            "\n",
            "Next Char Predictions: \n",
            " 'YUJMLUqevvMAS4rR.EbYzxm1snx fkkbIQYo\\nvvv2u1EK\\ncKtvm tDU. WqRUeRmxL10sfpmf.1h\\nuiGxtMeOs0llMFMH0c1vsUE'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugr2fwp1bR6f",
        "colab_type": "code",
        "outputId": "40e02e65-f7a6-4341-d32f-d6985bc88d6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 59)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.076025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7XfDECSbUKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG36rDe1bXeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cGZ5q6FbbhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS=100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHuZ70DUbe8f",
        "colab_type": "code",
        "outputId": "5484d4fd-a05d-4e85-a001-6fb40c881958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 3s 139ms/step - loss: 2.9108\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 2.5989\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 2.4343\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 3s 138ms/step - loss: 2.3486\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 2.2807\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 2.2043\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 2.1312\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 3s 150ms/step - loss: 2.0575\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 1.9853\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 1.9203\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 1.8606\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 1.8078\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 1.7565\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 1.7066\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 1.6650\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 1.6200\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 3s 140ms/step - loss: 1.5782\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 1.5388\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 1.4995\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 1.4593\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - 3s 148ms/step - loss: 1.4212\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 1.3848\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 1.3491\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 1.3167\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - 3s 148ms/step - loss: 1.2793\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 1.2447\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - 3s 153ms/step - loss: 1.2068\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 1.1731\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - 3s 156ms/step - loss: 1.1341\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - 3s 148ms/step - loss: 1.1031\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 1.0593\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 1.0188\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.9827\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.9412\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.8948\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - 3s 155ms/step - loss: 0.8512\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - 3s 148ms/step - loss: 0.8073\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - 3s 150ms/step - loss: 0.7647\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.7210\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - 3s 153ms/step - loss: 0.6748\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.6333\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - 3s 148ms/step - loss: 0.5913\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - 3s 154ms/step - loss: 0.5521\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - 3s 152ms/step - loss: 0.5119\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - 3s 150ms/step - loss: 0.4775\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.4474\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - 3s 152ms/step - loss: 0.4141\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.3886\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - 3s 148ms/step - loss: 0.3663\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - 3s 157ms/step - loss: 0.3459\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - 3s 149ms/step - loss: 0.3284\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - 3s 161ms/step - loss: 0.3139\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.2998\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - 3s 150ms/step - loss: 0.2885\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - 3s 154ms/step - loss: 0.2785\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.2649\n",
            "Epoch 58/100\n",
            "21/21 [==============================] - 3s 153ms/step - loss: 0.2585\n",
            "Epoch 59/100\n",
            "21/21 [==============================] - 3s 152ms/step - loss: 0.2524\n",
            "Epoch 60/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.2465\n",
            "Epoch 61/100\n",
            "21/21 [==============================] - 3s 160ms/step - loss: 0.2386\n",
            "Epoch 62/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.2365\n",
            "Epoch 63/100\n",
            "21/21 [==============================] - 3s 161ms/step - loss: 0.2291\n",
            "Epoch 64/100\n",
            "21/21 [==============================] - 3s 154ms/step - loss: 0.2245\n",
            "Epoch 65/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.2195\n",
            "Epoch 66/100\n",
            "21/21 [==============================] - 3s 156ms/step - loss: 0.2187\n",
            "Epoch 67/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.2153\n",
            "Epoch 68/100\n",
            "21/21 [==============================] - 3s 156ms/step - loss: 0.2108\n",
            "Epoch 69/100\n",
            "21/21 [==============================] - 3s 155ms/step - loss: 0.2073\n",
            "Epoch 70/100\n",
            "21/21 [==============================] - 3s 148ms/step - loss: 0.2053\n",
            "Epoch 71/100\n",
            "21/21 [==============================] - 3s 163ms/step - loss: 0.2047\n",
            "Epoch 72/100\n",
            "21/21 [==============================] - 3s 149ms/step - loss: 0.1975\n",
            "Epoch 73/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.1947\n",
            "Epoch 74/100\n",
            "21/21 [==============================] - 3s 160ms/step - loss: 0.1938\n",
            "Epoch 75/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1921\n",
            "Epoch 76/100\n",
            "21/21 [==============================] - 3s 153ms/step - loss: 0.1913\n",
            "Epoch 77/100\n",
            "21/21 [==============================] - 3s 152ms/step - loss: 0.1878\n",
            "Epoch 78/100\n",
            "21/21 [==============================] - 3s 149ms/step - loss: 0.1871\n",
            "Epoch 79/100\n",
            "21/21 [==============================] - 3s 152ms/step - loss: 0.1839\n",
            "Epoch 80/100\n",
            "21/21 [==============================] - 3s 158ms/step - loss: 0.1852\n",
            "Epoch 81/100\n",
            "21/21 [==============================] - 3s 153ms/step - loss: 0.1812\n",
            "Epoch 82/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.1817\n",
            "Epoch 83/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.1806\n",
            "Epoch 84/100\n",
            "21/21 [==============================] - 3s 150ms/step - loss: 0.1780\n",
            "Epoch 85/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1763\n",
            "Epoch 86/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.1728\n",
            "Epoch 87/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1712\n",
            "Epoch 88/100\n",
            "21/21 [==============================] - 3s 148ms/step - loss: 0.1711\n",
            "Epoch 89/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1713\n",
            "Epoch 90/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1702\n",
            "Epoch 91/100\n",
            "21/21 [==============================] - 3s 150ms/step - loss: 0.1680\n",
            "Epoch 92/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.1654\n",
            "Epoch 93/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.1656\n",
            "Epoch 94/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.1651\n",
            "Epoch 95/100\n",
            "21/21 [==============================] - 3s 148ms/step - loss: 0.1640\n",
            "Epoch 96/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1631\n",
            "Epoch 97/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.1617\n",
            "Epoch 98/100\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.1607\n",
            "Epoch 99/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1593\n",
            "Epoch 100/100\n",
            "21/21 [==============================] - 3s 148ms/step - loss: 0.1607\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
            "21/21 [==============================] - 5s 232ms/step - loss: 4.0889\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 2.9241\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 2.6075\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 2.4381\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 2.3491\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 2.2808\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 2.2099\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 2.1365\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 2.0658\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 1.9999\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 1.9318\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 1.8728\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 1.8212\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - 3s 149ms/step - loss: 1.7693\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 1.7191\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 1.6747\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 1.6314\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 1.5864\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 1.5501\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 1.5082\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 1.4670\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 1.4273\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 1.3893\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 1.3574\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 1.3200\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 1.2815\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 1.2498\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 1.2125\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 1.1785\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 1.1393\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 1.1003\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 1.0598\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 1.0213\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.9791\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.9352\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.8943\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.8453\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.8031\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.7572\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.7118\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.6689\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.6172\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - 3s 141ms/step - loss: 0.5756\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - 3s 142ms/step - loss: 0.5378\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.4994\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - 3s 143ms/step - loss: 0.4682\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.4347\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.4024\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.3797\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.3534\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.3336\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.3161\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.3028\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - 3s 158ms/step - loss: 0.2914\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.2811\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.2684\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.2624\n",
            "Epoch 58/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.2517\n",
            "Epoch 59/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.2453\n",
            "Epoch 60/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.2394\n",
            "Epoch 61/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.2334\n",
            "Epoch 62/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.2329\n",
            "Epoch 63/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.2278\n",
            "Epoch 64/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.2221\n",
            "Epoch 65/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.2172\n",
            "Epoch 66/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.2142\n",
            "Epoch 67/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.2114\n",
            "Epoch 68/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.2107\n",
            "Epoch 69/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.2031\n",
            "Epoch 70/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.2007\n",
            "Epoch 71/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.1978\n",
            "Epoch 72/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1961\n",
            "Epoch 73/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.1947\n",
            "Epoch 74/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.1911\n",
            "Epoch 75/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.1892\n",
            "Epoch 76/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1881\n",
            "Epoch 77/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.1860\n",
            "Epoch 78/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.1862\n",
            "Epoch 79/100\n",
            "21/21 [==============================] - 3s 148ms/step - loss: 0.1833\n",
            "Epoch 80/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1821\n",
            "Epoch 81/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1795\n",
            "Epoch 82/100\n",
            "21/21 [==============================] - 3s 150ms/step - loss: 0.1813\n",
            "Epoch 83/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1742\n",
            "Epoch 84/100\n",
            "21/21 [==============================] - 3s 155ms/step - loss: 0.1728\n",
            "Epoch 85/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.1737\n",
            "Epoch 86/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.1721\n",
            "Epoch 87/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.1713\n",
            "Epoch 88/100\n",
            "21/21 [==============================] - 3s 149ms/step - loss: 0.1702\n",
            "Epoch 89/100\n",
            "21/21 [==============================] - 3s 148ms/step - loss: 0.1689\n",
            "Epoch 90/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.1672\n",
            "Epoch 91/100\n",
            "21/21 [==============================] - 3s 147ms/step - loss: 0.1629\n",
            "Epoch 92/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.1642\n",
            "Epoch 93/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1644\n",
            "Epoch 94/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.1620\n",
            "Epoch 95/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1603\n",
            "Epoch 96/100\n",
            "21/21 [==============================] - 3s 144ms/step - loss: 0.1617\n",
            "Epoch 97/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.1619\n",
            "Epoch 98/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1591\n",
            "Epoch 99/100\n",
            "21/21 [==============================] - 3s 145ms/step - loss: 0.1592\n",
            "Epoch 100/100\n",
            "21/21 [==============================] - 3s 146ms/step - loss: 0.1548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoZbBnn3qqc8",
        "colab_type": "code",
        "outputId": "d9fb0445-a71a-48a4-b5b2-11503253091d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_100'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_100'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfYVRq_BqyWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnjEjER1q0sv",
        "colab_type": "code",
        "outputId": "a2fa37cd-011c-4e90-f42a-5a2ff5ebe38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 256)            15104     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 59)             60475     \n",
            "=================================================================\n",
            "Total params: 4,013,883\n",
            "Trainable params: 4,013,883\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (1, None, 256)            15104     \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (1, None, 59)             60475     \n",
            "=================================================================\n",
            "Total params: 4,013,883\n",
            "Trainable params: 4,013,883\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PkXuaDQq578",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 1000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the word returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted word as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWd1xCAJrKdx",
        "colab_type": "code",
        "outputId": "ee5a8ccd-6f7c-4aeb-c4a5-746ae7bef09b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "print(generate_text(model, start_string=u\"Jekyll\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jekyll   s favourite  of a man who could afford to laught the\n",
            "veitof Hyde.   \n",
            "\n",
            "   Hm     said Mr. Utterson.    What sort of a way  what and you to be sure  but in the lawyer     I see you have some good reason  Poole  I see\n",
            "there is something seriously amiss. Try   pread cabitele was so much dives and hands. St sight  hid bear\n",
            "without efficiency. You will learn from Poole how I have had London. But tonight there was a shudder\n",
            "in his blood  the face of Hyde sat heavy on his memory  he sat or oue  poor Hyde. How was this to be explained \n",
            "I asked myself  and then  wreck of my chair  or continue  with\n",
            "the most strained and fearstruck ecstasy of listening  to pavement on Jekyll   s own confession  I bring the life of that unhappy Henry Jekyll to be seen by foul   if Jekyll will only\n",
            "let me.    For once more he ored see was of silver  hand of Edward Hyde. Yes \n",
            "I shall sive him and began to whisper      is a tall  fine build of a man \n",
            "and tht walk with some degree of steadiness\n",
            "among temptations  a\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}